% SPDX-FileCopyrightText: Copyright (c) 2023-2025 Yegor Bugayenko
% SPDX-License-Identifier: MIT

\documentclass{article}
\usepackage{../lecture-notes/notes}
\usepackage[russian,english]{babel}
\newcommand*\thetitle{Static Analysis}
\begin{document}

\lnTitlePage{23}{24}{QK2XQvYoEpQ}

\lnThought{Analyzing a program before it starts running may help detect its defects earlier.}

\lnQuote
  [Steven Johnson]
  {steven-johnson}
  {\textbf{Lint} is a command which examines C source programs, detecting a number of \ul{bugs} and \ul{obscurities}. It enforces the type rules of C more strictly than the C compilers. It may also be used to enforce a number of \ul{portability restrictions} involved in moving programs between different machines and/or operating systems. Another option detects a number of \ul{wasteful}, or \ul{error prone}, constructions which nevertheless are, strictly speaking, legal.}
  {johnson1977lint}
\lnPitch{
  \begin{multicols}{2}
  \includegraphics[width=.95\linewidth]{lint-material.png}
  \par\columnbreak\par
  ``This is \ul{dryer lint} (({\selectlanguage{russian}ворс})), which is scraped out of a clothes dryer filter after it has dried a few loads. The idea of the Lint tool is to get this sort of stuff out of your code by being very pedantic about warnings and advice on possible bad code constructions.'' ---
  \href{https://www.quora.com/In-programming-where-does-the-term-lint-come-from}{Quora}
  \end{multicols}}

\pptBanner{Some Types of Bugs to Be Found by Static Analysis}
\begin{pptWide}{3}
Unreachable Code:
{\small\begin{ffcode}
int a = 10;
if (a > 20) {
  (*@\textcolor{orange}{a = a + 1;}@*)
}
\end{ffcode}
}\par
Uninitialized Variable:\par
{\small\begin{ffcode}
int x;
int y = (*@\textcolor{orange}{x}@*) + 42;
print(y);
\end{ffcode}
}
\par\columnbreak\par
Division by Zero:\par
{\small\begin{ffcode}
int f(int x) {
  return (*@\textcolor{orange}{42 / x}@*);
}
\end{ffcode}
}\par
Integer Overflow:\par
{\small\begin{ffcode}
var x: u8 = 142;
x = x (*@\textcolor{orange}{* 2}@*);
\end{ffcode}
}
\par\columnbreak\par
Endless Loop:
{\small\begin{ffcode}
int x = 5;
int y = 0;
while ((*@\textcolor{orange}{x > 0}@*)) {
  y = y + x;
}
\end{ffcode}
}\par
Buffer Overflow:
{\small\begin{ffcode}
#include <stdio.h>
char buf[16];
fgets(buf, (*@\textcolor{orange}{1024}@*), stdin);
\end{ffcode}
}
\end{pptWide}
\plush{}

\pptBanner{Inter-procedural Analysis}
\begin{pptWide}{3}
Unused Global Var:
{\small\begin{ffcode}
int x;
int foo() {
  return 42;
}

int bar(int x) {
  return (*@\textcolor{orange}{x}@*) + 1;
}
\end{ffcode}
}
\par\columnbreak\par
Endless Recursion:\par
{\small\begin{ffcode}
int foo(int n) {
  return bar(n - 1);
}

int bar(int n) {
  return foo(n + 1);
}
\end{ffcode}
}
\par\columnbreak\par
Pointer Dereferencing:
{\small\begin{ffcode}
int foo() {
  return *bar();
}

int* bar() {
  return (*@\textcolor{orange}{0}@*);
}
\end{ffcode}
}
\end{pptWide}
\plush{}

\pptBanner{Violations, Smells, Bugs}
\begin{multicols}{3}
Style Violation:
{\small\begin{ffcode}
int f
  (int x)
{
     return 42/x;
}
\end{ffcode}
}
\par\columnbreak\par
Code Smell:\par
{\small\begin{ffcode}
int f(int x) {
  return 42.0 / x;
}
\end{ffcode}
}
\par\columnbreak\par
Bug:\par
{\small\begin{ffcode}
int f(int x) {
  return 42 / x;
}
\end{ffcode}
}
\end{multicols}
{\scriptsize\color{red}\ttfamily\begin{multicols}{3}
Line 2: Indentation \\
Line 3: Curled bracket \\
Line 4: Indentation
\par\columnbreak\par
Line 2: Implicit type \\
cast from float to int
\par\columnbreak\par
Line 2: Division by zero
\end{multicols}}
\plush{}

\lnThought{Static analyzers can fail in two ways: by falsely reporting bugs or by missing them.}

\lnQuote
  [Brian Chess]
  {brian-chess}
  {Beware of any tool that says something like, `zero defects found, your program is, rather, now secure.' The appropriate output is, `sorry, \ul{couldn’t find} any more bugs.'}
  {chess2004static}

\pptBanner{False Negative vs. False Positive}
\begin{multicols}{2}
{\small\begin{ffcode}
int f(int x) {
  return 42 / x;
}
\end{ffcode}
}
\par\columnbreak\par
\textcolor{green}{\nospell{\textbf{T}rue \textbf{P}ositive}} (TP): \\ ``Division by zero''\par
\textcolor{red}{\nospell{\textbf{F}alse \textbf{P}ositive}} (FP): \\ ``Integer overflow''\par
\textcolor{green}{\nospell{\textbf{T}rue \textbf{N}egative}} (TN): \\ ``No buffer overflow''\par
\textcolor{red}{\nospell{\textbf{F}alse \textbf{N}egative}} (FN): \\ ``No errors at all''\par
\end{multicols}
\plush{}

\plush{
  \pptBanner{Precision \& Recall}
  \emph{Precision} is the fraction of relevant instances among the retrieved instances (100\% precision means \emph{soundness}).
  \emph{Recall} is the fraction of relevant instances that were retrieved (100\% recall means \emph{completeness}).
  \begin{pptWideOne}
  \begin{gather*}
  \text{Precision} = \frac{TP}{TP + FP}
  \quad\quad
  \text{Recall} = \frac{TP}{TP + FN}
  \quad\quad
  \text{Accuracy} = \frac{TP + TN}{TP + TN + FP + FN}
  \\[12pt]
  \text{F1} = \frac{2 \times TP}{2 \times TP + FP + FN}
  \\
  \end{gather*}
  \end{pptWideOne}}

\lnQuote
  [Sunghun Kim]
  {sunghun-kim}
  {About \ul{90\%} of warnings remain in the program or are removed during non-fix changes --- likely \ul{false positive} warnings.}
  {kim2007warnings}

\lnQuote
  [Brittany Johnson]
  {brittany-johnson}
  {Our results confirmed that \ul{false positives} and developer \ul{overload} play a part in developers' dissatisfaction with current static analysis tools.}
  {johnson2013don}

\lnQuote
  [Benjamin Livshits]
  {benjamin-livshits}
  {We are not aware of a single realistic whole-program analysis tool that does not \ul{purposely} make unsound choices... \textcolor{orange}{Soundness} is \ul{not even necessary} for most modern analysis applications, however, as many clients can tolerate unsoundness.}
  {livshits2015defense}

\lnQuote
  [Steven Arzt]
  {steven-arzt}
  {In our experiments on DroidBench examples, TASMAN \ul{reduces} the number of false positives by about 80\% \ul{without pruning} any true positives.}
  {arzt2015using}

\lnQuote
  [Nachiappan Nagappan]
  {nachiappan-nagappan}
  {Our results show that the static analysis defect density is \ul{correlated} at statistically significant levels to the pre-release defect density determined by various testing activities. Further, the static analysis defect density can be used to \ul{predict} the pre-release defect density with a high degree of sensitivity.}
  {nagappan2005static}

\lnThought{Existing open-source static analyzers are less powerful than commercial ones.}

\plush{\pptBanner{My Favorite Static Analyzers}
\begin{itemize}
  \item Java:
    \href{https://spotbugs.github.io/}{SpotBugs},
    \href{https://checkstyle.sourceforge.io/}{Checkstyle},
    \href{https://pmd.github.io/}{PMD},
    and
    \href{https://www.qulice.com}{Qulice} for Java
  \item C++:
    \href{https://clang.llvm.org/extra/clang-tidy/}{Clang-Tidy}
  \item Rust:
    \href{https://github.com/rust-lang/rust-clippy}{clippy}
  \end{itemize}
  \par
  There are many more of them: \newline \url{https://github.com/analysis-tools-dev/static-analysis}}

\plush{\pptBanner{Some Static Analysis Mechanisms}
\begin{itemize}
  \item Data Flow Analysis
  \item Symbolic Execution
  \item Model Checking
  \item Taint Analysis
  \end{itemize}\par
  You may want to watch my ``\href{https://github.com/yegor256/ppa}{Practical Program Analysis}'' course.}

\plush{\pptBanner{For some tools, you have to pay:}
\begin{itemize}
  \setlength\itemsep{0em}
  \item Coverity by \href{https://scan.coverity.com/}{Synopsys} (US)
  \item Klockwork by \href{https://www.perforce.com/}{Perforce} (US)
  \item Fortify by \href{https://www.microfocus.com/}{Micro Focus} (UK)
  \item \href{https://checkmarx.com/}{Checkmarx} (US)
  \item \href{https://www.veracode.com/}{Veracode} (US)
  \item \href{https://snyk.io/}{Snyk} (US)
  \item \href{https://pvs-studio.com/en/pvs-studio/}{PVS-Studio} (Russia)
  \end{itemize}\par
  Usually, up to \ul{\$3,000} per developer per year.}

\lnPitch{
  \pptBanner{SARIF}
  \begin{multicols}{2}
  \includegraphics[width=.95\linewidth]{sarif.png}
  \par\columnbreak\par
  ``This document defines a standard format for the output of static analysis tools.''
  \lnSource{sarif2023}
  \end{multicols}}

\lnThought{Some bugs are significant enough to be assigned unique identifiers, such as CVEs (Common Vulnerabilities and Exposures).}

\lnPitch{
  \pptBanner{CVE Databases:}
  \begin{itemize}
  \item \href{https://www.cve.org}{CVE.org}
  \item National Vulnerability Database (\href{https://nvd.nist.gov/vuln}{NVD})
  \item \href{https://osv.dev/}{OSV.dev}
  \item \href{https://www.cvedetails.com/}{CVEDetails.com}
  \end{itemize}}

\lnThought{How about asking static analyzers to detect good code instead of bad code?}

\lnQuote
  [\nospell{Florian Oberm{\"u}ller}]
  {florian-obermuller}
  {We introduce the concept of \ul{code perfumes} as the counterpart to \ul{code smells}, indicating the correct application of programming practices considered to be good. Using a catalogue of 25 code perfumes for, we empirically demonstrate that these represent frequent practices in, and we find that better programs indeed contain more code perfumes.}
  {obermuller2021code}

\end{document}
